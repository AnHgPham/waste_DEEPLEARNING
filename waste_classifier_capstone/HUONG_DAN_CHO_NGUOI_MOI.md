# ğŸ“ HÆ¯á»šNG DáºªN PHÃ‚N LOáº I RÃC THáº¢I Báº°NG AI - CHO NGÆ¯á»œI Má»šI Há»ŒC

> **Dá»± Ã¡n Capstone: Há»‡ thá»‘ng phÃ¢n loáº¡i rÃ¡c tháº£i tá»± Ä‘á»™ng sá»­ dá»¥ng Deep Learning**
>
> ğŸ“Œ **DÃ nh cho ngÆ°á»i má»›i báº¯t Ä‘áº§u há»c Machine Learning/Deep Learning**

---

## ğŸ“– Má»¤C Lá»¤C

1. [Dá»± Ã¡n nÃ y lÃ m gÃ¬?](#1-dá»±-Ã¡n-nÃ y-lÃ m-gÃ¬)
2. [CÃ i Ä‘áº·t vÃ  chuáº©n bá»‹](#2-cÃ i-Ä‘áº·t-vÃ -chuáº©n-bá»‹)
3. [Cáº¥u trÃºc dá»± Ã¡n](#3-cáº¥u-trÃºc-dá»±-Ã¡n)
4. [HÆ°á»›ng dáº«n cháº¡y tá»«ng bÆ°á»›c](#4-hÆ°á»›ng-dáº«n-cháº¡y-tá»«ng-bÆ°á»›c)
5. [Giáº£i thÃ­ch cÃ¡ch hoáº¡t Ä‘á»™ng](#5-giáº£i-thÃ­ch-cÃ¡ch-hoáº¡t-Ä‘á»™ng)
6. [Káº¿t quáº£ mong Ä‘á»£i](#6-káº¿t-quáº£-mong-Ä‘á»£i)
7. [Xá»­ lÃ½ lá»—i thÆ°á»ng gáº·p](#7-xá»­-lÃ½-lá»—i-thÆ°á»ng-gáº·p)
8. [TÃ¬m hiá»ƒu thÃªm](#8-tÃ¬m-hiá»ƒu-thÃªm)

---

## 1. Dá»° ÃN NÃ€Y LÃ€M GÃŒ?

### ğŸ¯ Má»¥c tiÃªu
XÃ¢y dá»±ng má»™t há»‡ thá»‘ng AI cÃ³ thá»ƒ **tá»± Ä‘á»™ng nháº­n diá»‡n vÃ  phÃ¢n loáº¡i rÃ¡c tháº£i** thÃ nh 10 loáº¡i:

```
ğŸ“¦ 10 loáº¡i rÃ¡c:
   1. ğŸ”‹ Pin (battery)
   2. ğŸ RÃ¡c há»¯u cÆ¡ (biological)
   3. ğŸ“¦ BÃ¬a carton (cardboard)
   4. ğŸ‘• Quáº§n Ã¡o (clothes)
   5. ğŸ¾ Thá»§y tinh (glass)
   6. ğŸ”© Kim loáº¡i (metal)
   7. ğŸ“„ Giáº¥y (paper)
   8. ğŸ¥¤ Nhá»±a (plastic)
   9. ğŸ‘Ÿ GiÃ y dÃ©p (shoes)
   10. ğŸ—‘ï¸ RÃ¡c tháº£i chung (trash)
```

### ğŸ’¡ á»¨ng dá»¥ng thá»±c táº¿
- **NhÃ  mÃ¡y tÃ¡i cháº¿**: Tá»± Ä‘á»™ng phÃ¢n loáº¡i rÃ¡c
- **ThÃ¹ng rÃ¡c thÃ´ng minh**: Nháº­n diá»‡n vÃ  hÆ°á»›ng dáº«n bá» Ä‘Ãºng thÃ¹ng
- **GiÃ¡o dá»¥c mÃ´i trÆ°á»ng**: Dáº¡y tráº» em phÃ¢n loáº¡i rÃ¡c
- **GiÃ¡m sÃ¡t mÃ´i trÆ°á»ng**: Thá»‘ng kÃª lÆ°á»£ng rÃ¡c tá»«ng loáº¡i

---

## 2. CÃ€I Äáº¶T VÃ€ CHUáº¨N Bá»Š

### BÆ°á»›c 1: CÃ i Ä‘áº·t Python (náº¿u chÆ°a cÃ³)

**Windows:**
```bash
# Táº£i Python 3.8+ tá»« python.org
# Chá»n "Add Python to PATH" khi cÃ i Ä‘áº·t
```

**macOS/Linux:**
```bash
# Python thÆ°á»ng Ä‘Ã£ cÃ³ sáºµn
python3 --version
```

### BÆ°á»›c 2: CÃ i Ä‘áº·t mÃ´i trÆ°á»ng áº£o (Virtual Environment)

```bash
# Di chuyá»ƒn vÃ o thÆ° má»¥c dá»± Ã¡n
cd D:\Downloads\waste_classifier_capstone\waste_classifier_capstone

# Táº¡o mÃ´i trÆ°á»ng áº£o
python -m venv venv

# KÃ­ch hoáº¡t mÃ´i trÆ°á»ng áº£o
# Windows:
venv\Scripts\activate

# macOS/Linux:
source venv/bin/activate
```

**ğŸ’¡ Táº¡i sao cáº§n mÃ´i trÆ°á»ng áº£o?**
- TÃ¡ch riÃªng cÃ¡c thÆ° viá»‡n cá»§a dá»± Ã¡n nÃ y vá»›i há»‡ thá»‘ng
- TrÃ¡nh xung Ä‘á»™t phiÃªn báº£n
- Dá»… dÃ ng chia sáº» dá»± Ã¡n

### BÆ°á»›c 3: CÃ i Ä‘áº·t thÆ° viá»‡n cáº§n thiáº¿t

```bash
# CÃ i táº¥t cáº£ thÆ° viá»‡n trong requirements.txt
pip install -r requirements.txt

# Hoáº·c cÃ i tá»«ng thÆ° viá»‡n chÃ­nh:
pip install tensorflow>=2.13.0
pip install opencv-python>=4.8.0
pip install matplotlib seaborn
pip install pandas numpy
pip install ultralytics  # YOLOv8
pip install jupyter
```

**â±ï¸ Thá»i gian**: Khoáº£ng 5-10 phÃºt (tÃ¹y tá»‘c Ä‘á»™ internet)

### BÆ°á»›c 4: Táº£i dá»¯ liá»‡u

**Dataset**: Khoáº£ng 19,760 áº£nh (1.6 GB)

```bash
# Táº£i tá»« Kaggle (cáº§n tÃ i khoáº£n Kaggle):
# https://www.kaggle.com/datasets/sumn2u/garbage-classification-v2

# Giáº£i nÃ©n vÃ o thÆ° má»¥c data/raw/
# Cáº¥u trÃºc:
data/raw/
  â”œâ”€â”€ battery/
  â”œâ”€â”€ biological/
  â”œâ”€â”€ cardboard/
  â”œâ”€â”€ clothes/
  â”œâ”€â”€ glass/
  â”œâ”€â”€ metal/
  â”œâ”€â”€ paper/
  â”œâ”€â”€ plastic/
  â”œâ”€â”€ shoes/
  â””â”€â”€ trash/
```

---

## 3. Cáº¤U TRÃšC Dá»° ÃN

```
waste_classifier_capstone/
â”‚
â”œâ”€â”€ ğŸ“ src/                      â† MÃ£ nguá»“n chÃ­nh (modules)
â”‚   â”œâ”€â”€ config.py                â† Cáº¥u hÃ¬nh toÃ n bá»™ dá»± Ã¡n
â”‚   â”œâ”€â”€ data/                    â† Xá»­ lÃ½ dá»¯ liá»‡u
â”‚   â”œâ”€â”€ models/                  â† Kiáº¿n trÃºc mÃ´ hÃ¬nh AI
â”‚   â””â”€â”€ deployment/              â† Tá»‘i Æ°u hÃ³a model
â”‚
â”œâ”€â”€ ğŸ“ scripts/                  â† Scripts cháº¡y tá»«ng bÆ°á»›c
â”‚   â”œâ”€â”€ 01_data_exploration.py   â† KhÃ¡m phÃ¡ dá»¯ liá»‡u
â”‚   â”œâ”€â”€ 02_preprocessing.py      â† Chia dá»¯ liá»‡u train/val/test
â”‚   â”œâ”€â”€ 03_baseline_training.py  â† Train mÃ´ hÃ¬nh cÆ¡ báº£n
â”‚   â”œâ”€â”€ 04_transfer_learning.py  â† Train mÃ´ hÃ¬nh nÃ¢ng cao
â”‚   â”œâ”€â”€ 05_realtime_detection.py â† Nháº­n diá»‡n real-time
â”‚   â””â”€â”€ 06_model_optimization.py â† Tá»‘i Æ°u model
â”‚
â”œâ”€â”€ ğŸ“ notebooks/                â† Jupyter notebooks (há»c táº­p)
â”‚   â”œâ”€â”€ W1_Data_Exploration.ipynb
â”‚   â”œâ”€â”€ W1_Preprocessing.ipynb
â”‚   â”œâ”€â”€ W1_Baseline_CNN.ipynb
â”‚   â”œâ”€â”€ W2_Feature_Extraction.ipynb
â”‚   â”œâ”€â”€ W2_Fine_Tuning.ipynb
â”‚   â”œâ”€â”€ W3_Integration.ipynb
â”‚   â””â”€â”€ W4_Model_Optimization.ipynb
â”‚
â”œâ”€â”€ ğŸ“ data/                     â† Dá»¯ liá»‡u
â”‚   â”œâ”€â”€ raw/                     â† áº¢nh gá»‘c (19,760 áº£nh)
â”‚   â””â”€â”€ processed/               â† áº¢nh Ä‘Ã£ chia (train/val/test)
â”‚
â”œâ”€â”€ ğŸ“ outputs/                  â† Káº¿t quáº£
â”‚   â”œâ”€â”€ models/                  â† Models Ä‘Ã£ train
â”‚   â”œâ”€â”€ reports/                 â† Biá»ƒu Ä‘á»“, bÃ¡o cÃ¡o
â”‚   â””â”€â”€ logs/                    â† Logs training
â”‚
â””â”€â”€ ğŸ“„ main.py                   â† Cháº¡y má»i thá»© tá»« Ä‘Ã¢y!
```

---

## 4. HÆ¯á»šNG DáºªN CHáº Y Tá»ªNG BÆ¯á»šC

### ğŸš€ CÃCH 1: CHáº Y NHANH (Khuyáº¿n nghá»‹ cho ngÆ°á»i má»›i)

```bash
# Cháº¡y toÃ n bá»™ pipeline (cÃ¡ch Ä‘Æ¡n giáº£n nháº¥t)
python main.py --quick

# â±ï¸ Thá»i gian: 5-15 phÃºt (epochs giáº£m Ä‘á»ƒ test nhanh)
```

**Script nÃ y sáº½ tá»± Ä‘á»™ng:**
1. âœ… KhÃ¡m phÃ¡ dá»¯ liá»‡u
2. âœ… Chia dá»¯ liá»‡u train/val/test
3. âœ… Train baseline CNN (5 epochs)
4. âœ… Train MobileNetV2 (3+3 epochs)
5. âœ… ÄÃ¡nh giÃ¡ káº¿t quáº£

---

### ğŸ“ CÃCH 2: Há»ŒC Tá»ªNG TUáº¦N (Khuyáº¿n nghá»‹ Ä‘á»ƒ hiá»ƒu sÃ¢u)

#### **TUáº¦N 1: Dá»¯ liá»‡u vÃ  Baseline CNN** â±ï¸ ~1-2 giá»

```bash
# Cháº¡y cáº£ tuáº§n 1
python main.py --week 1

# Hoáº·c cháº¡y tá»«ng bÆ°á»›c:
# BÆ°á»›c 1: KhÃ¡m phÃ¡ dá»¯ liá»‡u
python main.py --explore
# â†’ Xem phÃ¢n bá»‘ classes, sample images
# â†’ Hiá»ƒu dataset cÃ³ bao nhiÃªu áº£nh má»—i loáº¡i

# BÆ°á»›c 2: Chia dá»¯ liá»‡u
python main.py --preprocess
# â†’ Chia 80% train / 10% validation / 10% test
# â†’ Táº¡o thÆ° má»¥c data/processed/

# BÆ°á»›c 3: Train baseline CNN
python main.py --train-baseline --epochs 30
# â†’ Train mÃ´ hÃ¬nh CNN tá»« Ä‘áº§u (from scratch)
# â†’ Káº¿t quáº£: ~85% accuracy
# â±ï¸ Thá»i gian: 30-60 phÃºt (tÃ¹y GPU/CPU)

# BÆ°á»›c 4: ÄÃ¡nh giÃ¡ baseline
python main.py --evaluate --model baseline
# â†’ Xem confusion matrix
# â†’ Xem accuracy tá»«ng class
```

**ğŸ“š Há»c gÃ¬ á»Ÿ tuáº§n 1?**
- CÃ¡ch khÃ¡m phÃ¡ vÃ  chuáº©n bá»‹ dá»¯ liá»‡u
- Kiáº¿n trÃºc CNN cÆ¡ báº£n
- Data augmentation (tÄƒng cÆ°á»ng dá»¯ liá»‡u)
- Overfitting vÃ  cÃ¡ch kháº¯c phá»¥c

---

#### **TUáº¦N 2: Transfer Learning** â±ï¸ ~1-2 giá»

```bash
# Cháº¡y cáº£ tuáº§n 2
python main.py --week 2

# Hoáº·c cháº¡y tá»«ng phase:
python main.py --train-transfer --phase1-epochs 20 --phase2-epochs 15
# â†’ Phase 1: Feature extraction (20 epochs)
# â†’ Phase 2: Fine-tuning (15 epochs)
# â†’ Káº¿t quáº£: ~95% accuracy
# â±ï¸ Thá»i gian: 40-90 phÃºt

# ÄÃ¡nh giÃ¡ transfer learning model
python main.py --evaluate --model mobilenetv2
```

**ğŸ“š Há»c gÃ¬ á»Ÿ tuáº§n 2?**
- Transfer learning lÃ  gÃ¬?
- MobileNetV2 architecture
- Feature extraction vs Fine-tuning
- Táº¡i sao accuracy tÄƒng tá»« 85% â†’ 95%?

---

#### **TUáº¦N 3: Real-time Detection** â±ï¸ ~30 phÃºt

```bash
# Cháº¡y real-time detection vá»›i webcam
python main.py --realtime --model mobilenetv2

# Hoáº·c dÃ¹ng video file:
python scripts/05_realtime_detection.py --video test.mp4

# â±ï¸ Real-time: 30+ FPS trÃªn CPU
```

**ğŸ“š Há»c gÃ¬ á»Ÿ tuáº§n 3?**
- YOLOv8 object detection
- Pipeline: Detect â†’ Crop â†’ Classify
- Real-time inference

---

#### **TUáº¦N 4: Model Optimization** â±ï¸ ~20 phÃºt

```bash
# Tá»‘i Æ°u model cho mobile/edge devices
python main.py --optimize --model mobilenetv2

# Káº¿t quáº£:
# â†’ mobilenetv2_final.keras: 9.2 MB
# â†’ mobilenetv2_fp32.tflite: 10.3 MB
# â†’ mobilenetv2_int8.tflite: 3.1 MB (giáº£m 74%!)
```

**ğŸ“š Há»c gÃ¬ á»Ÿ tuáº§n 4?**
- TensorFlow Lite conversion
- INT8 quantization
- Trade-off: Size vs Accuracy
- Deploy lÃªn Raspberry Pi, Android

---

### ğŸ““ CÃCH 3: Há»ŒC Báº°NG JUPYTER NOTEBOOKS (TÆ°Æ¡ng tÃ¡c)

```bash
# Khá»Ÿi Ä‘á»™ng Jupyter
jupyter notebook

# Má»Ÿ notebooks/ vÃ  cháº¡y tá»«ng cell:
# 1. W1_Data_Exploration.ipynb
# 2. W1_Preprocessing.ipynb
# 3. W1_Baseline_CNN.ipynb
# 4. W2_Feature_Extraction.ipynb
# 5. W2_Fine_Tuning.ipynb
# 6. W3_Integration.ipynb
# 7. W4_Model_Optimization.ipynb
```

**ğŸ’¡ Lá»£i Ã­ch:**
- Cháº¡y tá»«ng bÆ°á»›c, xem káº¿t quáº£ ngay
- Sá»­a code vÃ  thá»­ nghiá»‡m
- Visualize dá»¯ liá»‡u vÃ  káº¿t quáº£

---

## 5. GIáº¢I THÃCH CÃCH HOáº T Äá»˜NG

### ğŸ§  A. Baseline CNN (MÃ´ hÃ¬nh cÆ¡ báº£n)

**Kiáº¿n trÃºc:**
```
Input Image (224Ã—224Ã—3)
    â†“
Conv Block 1: 32 filters
    â†“
Conv Block 2: 64 filters
    â†“
Conv Block 3: 128 filters
    â†“
Conv Block 4: 256 filters
    â†“
Global Average Pooling
    â†“
Dense Layer (128 units)
    â†“
Output (10 classes)
```

**Giáº£i thÃ­ch:**
- **Conv Blocks**: TrÃ­ch xuáº¥t features (Ä‘Æ°á»ng nÃ©t, hÃ¬nh dáº¡ng, texture)
- **Filters tÄƒng dáº§n**: 32â†’64â†’128â†’256 (há»c features tá»« Ä‘Æ¡n giáº£n â†’ phá»©c táº¡p)
- **MaxPooling**: Giáº£m kÃ­ch thÆ°á»›c, giá»¯ thÃ´ng tin quan trá»ng
- **Dropout**: NgÄƒn overfitting (há»c thuá»™c lÃ²ng)
- **Káº¿t quáº£**: ~85% accuracy vá»›i ~1.2M parameters

**Code chÃ­nh**: `src/models/baseline.py`

---

### ğŸš€ B. Transfer Learning (MÃ´ hÃ¬nh nÃ¢ng cao)

**MobileNetV2 - Pretrained trÃªn ImageNet**

```
MobileNetV2 Base (Frozen)  â† ÄÃ£ há»c 1000 classes tá»« ImageNet
    â†“                        (14 triá»‡u áº£nh!)
Custom Classification Head
    â†“
Dense(256) + BatchNorm + Dropout
    â†“
Dense(128) + BatchNorm + Dropout
    â†“
Output (10 classes - waste)
```

**Two-Phase Training:**

**Phase 1: Feature Extraction (20 epochs)**
```python
# ÄÃ³ng bÄƒng base model â†’ CHá»ˆ train classification head
freeze_base = True
learning_rate = 0.0001  # LR tháº¥p
# â†’ Base model extract features
# â†’ Classification head há»c phÃ¢n loáº¡i rÃ¡c
```

**Phase 2: Fine-Tuning (15 epochs)**
```python
# Má»Ÿ khÃ³a top 30 layers â†’ Fine-tune cho waste domain
unfreeze_top_30_layers()
learning_rate = 0.00001  # LR ráº¥t tháº¥p
# â†’ Adapt features cho waste images
# â†’ Cáº£i thiá»‡n accuracy
```

**Táº¡i sao tá»‘t hÆ¡n?**
- âœ… MobileNetV2 Ä‘Ã£ há»c **general features** (cáº¡nh, texture, hÃ¬nh dáº¡ng)
- âœ… Ta chá»‰ cáº§n dáº¡y nÃ³ **phÃ¢n biá»‡t rÃ¡c** â†’ há»c nhanh hÆ¡n
- âœ… Ãt dá»¯ liá»‡u hÆ¡n, accuracy cao hÆ¡n: 85% â†’ **95%**

**Code chÃ­nh**: `src/models/transfer.py`

---

### ğŸ“¹ C. Real-time Detection

**Pipeline:**

```
1. Webcam/Video Frame
    â†“
2. YOLOv8 Detect Objects
    â†“ (tÃ¬m vá»‹ trÃ­ objects: bounding boxes)
3. Crop Each Object
    â†“
4. MobileNetV2 Classify
    â†“ (cardboard? plastic? glass?)
5. Draw Boxes + Labels
    â†“
6. Display Real-time
```

**VÃ­ dá»¥:**
```
Frame â†’ YOLO detect 3 objects
  â†“
Object 1 (box [100,50,200,150]) â†’ Classify â†’ "plastic" 95%
Object 2 (box [250,80,350,180]) â†’ Classify â†’ "paper" 87%
Object 3 (box [400,100,500,200]) â†’ Classify â†’ "cardboard" 92%
  â†“
Draw boxes with labels â†’ Display
```

**Code chÃ­nh**: `scripts/05_realtime_detection.py`

---

### âš¡ D. Model Optimization

**Má»¥c tiÃªu**: Deploy lÃªn thiáº¿t bá»‹ edge (mobile, Raspberry Pi)

**Quy trÃ¬nh:**

```
1. Keras Model (9.2 MB, FP32)
    â†“ TFLite Conversion
2. TFLite FP32 Model (10.3 MB)
    â†“ INT8 Quantization
3. TFLite INT8 Model (3.1 MB)  â† Giáº£m 74% size!
```

**INT8 Quantization:**
- **FP32**: 32-bit floating point (chÃ­nh xÃ¡c cao, náº·ng)
- **INT8**: 8-bit integer (nháº¹ hÆ¡n, nhanh hÆ¡n)
- **Trade-off**: Size giáº£m 74%, accuracy chá»‰ giáº£m 1% (95%â†’94%)

**Code chÃ­nh**: `src/deployment/optimize.py`

---

## 6. Káº¾T QUáº¢ MONG Äá»¢I

### ğŸ“Š Model Performance

| Model | Accuracy | Size | Inference Time |
|-------|----------|------|----------------|
| Baseline CNN | ~85% | 4.8 MB | 15 ms |
| MobileNetV2 | ~95% | 9.2 MB | 20 ms |
| MobileNetV2 (INT8) | ~94% | **2.4 MB** | **8 ms** |

### ğŸ“ Files Ä‘Æ°á»£c táº¡o ra

```
outputs/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ baseline_final.keras            (4.8 MB)
â”‚   â”œâ”€â”€ mobilenetv2_phase1.keras        (14 MB)
â”‚   â”œâ”€â”€ mobilenetv2_final.keras         (9.2 MB)
â”‚   â”œâ”€â”€ mobilenetv2_fp32.tflite         (10.3 MB)
â”‚   â””â”€â”€ mobilenetv2_int8.tflite         (2.4 MB) â† BEST!
â”‚
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ class_distribution.png          (biá»ƒu Ä‘á»“ phÃ¢n bá»‘ classes)
â”‚   â”œâ”€â”€ baseline_training_history.png   (loss/accuracy curves)
â”‚   â”œâ”€â”€ mobilenetv2_phase1_history.png
â”‚   â”œâ”€â”€ mobilenetv2_phase2_history.png
â”‚   â”œâ”€â”€ baseline_confusion_matrix.png   (ma tráº­n nháº§m láº«n)
â”‚   â””â”€â”€ mobilenetv2_confusion_matrix.png
â”‚
â””â”€â”€ logs/
    â””â”€â”€ training_*.log
```

### ğŸ¯ Accuracy per Class

**VÃ­ dá»¥ káº¿t quáº£ MobileNetV2:**
```
Class          Precision  Recall  F1-Score
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
battery           96%      94%     95%
biological        93%      91%     92%
cardboard         97%      96%     96%
clothes           94%      93%     93%
glass             96%      97%     96%
metal             95%      94%     94%
paper             96%      95%     95%
plastic           97%      98%     97%
shoes             92%      91%     91%
trash             89%      90%     89%
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Overall           95%      95%     95%
```

---

## 7. Xá»¬ LÃ Lá»–I THÆ¯á»œNG Gáº¶P

### âŒ Lá»—i 1: "No module named 'src'"

**NguyÃªn nhÃ¢n**: Cháº¡y script tá»« sai thÆ° má»¥c

**CÃ¡ch sá»­a:**
```bash
# Äáº£m báº£o Ä‘ang á»Ÿ thÆ° má»¥c gá»‘c dá»± Ã¡n
cd D:\Downloads\waste_classifier_capstone\waste_classifier_capstone
pwd  # Kiá»ƒm tra Ä‘Æ°á»ng dáº«n

# Cháº¡y láº¡i
python main.py --quick
```

---

### âŒ Lá»—i 2: "Raw data directory not found"

**NguyÃªn nhÃ¢n**: ChÆ°a táº£i dataset

**CÃ¡ch sá»­a:**
```bash
# 1. Táº£i dataset tá»« Kaggle
# 2. Giáº£i nÃ©n vÃ o data/raw/
# 3. Kiá»ƒm tra cáº¥u trÃºc:
ls data/raw/
# Pháº£i tháº¥y: battery/, biological/, cardboard/, ...
```

---

### âŒ Lá»—i 3: "Out of Memory" (GPU/CPU)

**NguyÃªn nhÃ¢n**: Batch size quÃ¡ lá»›n

**CÃ¡ch sá»­a:**
```python
# Edit src/config.py
BATCH_SIZE = 16  # Giáº£m tá»« 32 xuá»‘ng 16
```

---

### âŒ Lá»—i 4: Webcam khÃ´ng má»Ÿ Ä‘Æ°á»£c (Real-time)

**CÃ¡ch sá»­a:**
```bash
# Thá»­ camera index khÃ¡c
python scripts/05_realtime_detection.py --camera 1

# Hoáº·c dÃ¹ng video file
python scripts/05_realtime_detection.py --video test.mp4
```

---

### âŒ Lá»—i 5: "Weights only load failed" (YOLOv8)

**NguyÃªn nhÃ¢n**: PyTorch 2.6+ security update

**CÃ¡ch sá»­a**: âœ… **ÄÃƒ Tá»° Äá»˜NG Sá»¬A** trong code!
- File `src/detection/detection_utils.py` Ä‘Ã£ handle
- KhÃ´ng cáº§n lÃ m gÃ¬ thÃªm

---

### âŒ Lá»—i 6: Training quÃ¡ cháº­m

**Tá»‘i Æ°u hÃ³a:**

```python
# 1. Giáº£m epochs Ä‘á»ƒ test
python main.py --train-baseline --epochs 10  # Thay vÃ¬ 30

# 2. Giáº£m batch size
BATCH_SIZE = 16  # trong config.py

# 3. DÃ¹ng GPU náº¿u cÃ³
# TensorFlow tá»± Ä‘á»™ng detect GPU, chá»‰ cáº§n:
pip install tensorflow-gpu  # Náº¿u cÃ³ GPU NVIDIA
```

---

## 8. TÃŒM HIá»‚U THÃŠM

### ğŸ“– Äá»c lÃ½ thuyáº¿t

```
docs/theory/
â”œâ”€â”€ Week1_Data_and_Baseline.md      â† CNN basics
â”œâ”€â”€ Week2_Transfer_Learning.md       â† Transfer learning
â”œâ”€â”€ Week3_Realtime_Detection.md      â† YOLOv8
â””â”€â”€ Week4_Deployment.md              â† TFLite optimization
```

### ğŸ¥ KhÃ¡i niá»‡m cáº§n há»c

**Tuáº§n 1:**
- [ ] Convolutional Neural Networks (CNN)
- [ ] Convolutional layers, pooling layers
- [ ] Activation functions (ReLU, Softmax)
- [ ] Overfitting vÃ  regularization
- [ ] Data augmentation

**Tuáº§n 2:**
- [ ] Transfer learning
- [ ] Pretrained models (ImageNet)
- [ ] Feature extraction vs Fine-tuning
- [ ] Learning rate scheduling
- [ ] Freezing/unfreezing layers

**Tuáº§n 3:**
- [ ] Object detection
- [ ] YOLO (You Only Look Once)
- [ ] Bounding boxes vÃ  confidence scores
- [ ] Real-time inference

**Tuáº§n 4:**
- [ ] Model optimization
- [ ] TensorFlow Lite
- [ ] Quantization (FP32, INT8)
- [ ] Edge deployment

### ğŸ”— Resources há»¯u Ã­ch

**TensorFlow & Keras:**
- [TensorFlow Documentation](https://www.tensorflow.org/tutorials)
- [Keras Guide](https://keras.io/guides/)

**Transfer Learning:**
- [CS231n Transfer Learning](http://cs231n.github.io/transfer-learning/)

**YOLOv8:**
- [Ultralytics YOLOv8 Docs](https://docs.ultralytics.com/)

**TensorFlow Lite:**
- [TFLite Guide](https://www.tensorflow.org/lite/guide)

---

## 9. CÃC Lá»†NH THÆ¯á»œNG DÃ™NG

### Xem cáº¥u hÃ¬nh hiá»‡n táº¡i
```bash
python main.py --config
```

### Train vá»›i custom epochs
```bash
# Baseline vá»›i 50 epochs
python main.py --train-baseline --epochs 50

# Transfer learning vá»›i custom epochs cho cáº£ 2 phases
python main.py --train-transfer --phase1-epochs 25 --phase2-epochs 20
```

### Evaluate models
```bash
# ÄÃ¡nh giÃ¡ baseline
python main.py --evaluate --model baseline

# ÄÃ¡nh giÃ¡ MobileNetV2
python main.py --evaluate --model mobilenetv2
```

### Cháº¡y toÃ n bá»™ pipeline (full)
```bash
# Full pipeline vá»›i epochs Ä‘áº§y Ä‘á»§ (lÃ¢u!)
python main.py --all
# â±ï¸ Thá»i gian: 2-4 giá»
```

---

## 10. TIPS VÃ€ TRICKS

### ğŸ’¡ Tip 1: Báº¯t Ä‘áº§u vá»›i --quick
```bash
# Test má»i thá»© hoáº¡t Ä‘á»™ng trÆ°á»›c khi train lÃ¢u
python main.py --quick
```

### ğŸ’¡ Tip 2: DÃ¹ng Jupyter notebooks Ä‘á»ƒ há»c
```bash
# TÆ°Æ¡ng tÃ¡c, dá»… hiá»ƒu hÆ¡n
jupyter notebook
# Má»Ÿ notebooks/W1_Data_Exploration.ipynb
```

### ğŸ’¡ Tip 3: Monitor training
```bash
# Xem logs trong outputs/logs/
# Hoáº·c dÃ¹ng TensorBoard:
tensorboard --logdir=outputs/logs/
```

### ğŸ’¡ Tip 4: Backup models
```bash
# Copy models quan trá»ng ra ngoÃ i
cp outputs/models/mobilenetv2_final.keras ~/backup/
```

### ğŸ’¡ Tip 5: Thá»­ nghiá»‡m hyperparameters
```python
# Edit src/config.py:
LEARNING_RATE_BASELINE = 0.01  # Thá»­ LR khÃ¡c
BATCH_SIZE = 64  # Thá»­ batch size khÃ¡c
DROPOUT_RATE = 0.3  # Thá»­ dropout rate khÃ¡c

# Rá»“i train láº¡i:
python main.py --train-baseline
```

---

## ğŸ‰ CHÃšC Má»ªNG!

Báº¡n Ä‘Ã£ biáº¿t cÃ¡ch:
- âœ… Chuáº©n bá»‹ dá»¯ liá»‡u cho deep learning
- âœ… Train CNN tá»« Ä‘áº§u
- âœ… Ãp dá»¥ng transfer learning
- âœ… Real-time object detection
- âœ… Tá»‘i Æ°u model cho edge devices

**Next steps:**
- ğŸ“š Äá»c papers vá» MobileNetV2, YOLOv8
- ğŸ”¬ Thá»­ nghiá»‡m cÃ¡c architectures khÃ¡c (ResNet, EfficientNet)
- ğŸš€ Deploy lÃªn Raspberry Pi hoáº·c Android app
- ğŸ“Š Thá»­ dataset khÃ¡c
- ğŸ’¡ Ãp dá»¥ng cho bÃ i toÃ¡n thá»±c táº¿

---

## ğŸ“ Há»– TRá»¢

**Náº¿u gáº·p váº¥n Ä‘á»:**
1. Äá»c láº¡i pháº§n "Xá»­ lÃ½ lá»—i thÆ°á»ng gáº·p"
2. Check logs trong `outputs/logs/`
3. Äá»c README.md chÃ­nh
4. Má»Ÿ issue trÃªn GitHub (náº¿u cÃ³)

---

**ğŸ’ª ChÃºc báº¡n há»c tá»‘t vÃ  thÃ nh cÃ´ng vá»›i dá»± Ã¡n Deep Learning!**

> *"The best way to learn deep learning is by doing projects!"*

---

**ğŸ“… Version:** 2.0.0
**ğŸ“ Last Updated:** 2024
**ğŸ‘¤ Author:** Pham An
