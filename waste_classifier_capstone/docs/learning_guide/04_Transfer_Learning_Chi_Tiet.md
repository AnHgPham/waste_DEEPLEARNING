# ğŸ¯ TRANSFER LEARNING CHI TIáº¾T

**Thá»i gian:** 1.5 giá»
**Má»¥c tiÃªu:** Hiá»ƒu Transfer Learning vÃ  táº¡i sao nÃ³ tá»‘t hÆ¡n Baseline

---

## ğŸ“Œ 1. TRANSFER LEARNING LÃ€ GÃŒ? (15 phÃºt)

### **Äá»‹nh nghÄ©a Ä‘Æ¡n giáº£n:**

**Transfer Learning = DÃ¹ng láº¡i kiáº¿n thá»©c Ä‘Ã£ há»c tá»« task khÃ¡c**

```
VÃ­ dá»¥ thá»±c táº¿:

Báº¡n há»c lÃ¡i xe hÆ¡i:
  âœ“ ÄÃ£ biáº¿t giao thÃ´ng (tá»« Ä‘i xe mÃ¡y)
  âœ“ ÄÃ£ biáº¿t luáº­t Ä‘Æ°á»ng (tá»« há»c lÃ½ thuyáº¿t)
  â†’ Chá»‰ cáº§n há»c Ká»¸ NÄ‚NG Má»šI: Ä‘iá»u khiá»ƒn xe hÆ¡i
  â†’ Há»ŒC NHANH HÆ N ngÆ°á»i chÆ°a biáº¿t gÃ¬!

Transfer Learning:
  âœ“ Model Ä‘Ã£ biáº¿t nháº­n dáº¡ng áº£nh (tá»« ImageNet)
  âœ“ ÄÃ£ biáº¿t detect edges, textures (pre-trained)
  â†’ Chá»‰ cáº§n há»c Ká»¸ NÄ‚NG Má»šI: phÃ¢n loáº¡i rÃ¡c
  â†’ ACCURACY CAO HÆ N model train from scratch!
```

### **Trong dá»± Ã¡n:**

```
Baseline CNN (Train from Scratch):
  - Báº¯t Ä‘áº§u tá»« 0 (random weights)
  - Há»c Táº¤T Cáº¢ tá»« waste data (15,777 images)
  - Káº¿t quáº£: 79.59%

MobileNetV2 (Transfer Learning):
  - Báº¯t Ä‘áº§u tá»« pretrained weights (ImageNet)
  - ÄÃ£ há»c 1.2M images (1000 classes)
  - Chá»‰ cáº§n adapt cho waste data
  - Káº¿t quáº£: 93.90% (+14.31%!) âœ…
```

---

## ğŸ¤” 2. Táº I SAO Cáº¦N TRANSFER LEARNING? (20 phÃºt)

### **A. Data Limitation**

**Problem:**

```
Waste Classification Dataset:
  Train: 15,777 images
  Val:   1,972 images
  Test:  1,974 images
  Total: 19,723 images
  Classes: 10

â†’ KHÃ”NG Äá»¦ Ä‘á»ƒ train deep CNN from scratch!
```

**Táº¡i sao khÃ´ng Ä‘á»§?**

```
Deep CNN (nhÆ° MobileNetV2):
  - 53 layers
  - 2.7M parameters
  - Cáº§n há»c complex patterns

Rule of thumb:
  Parameters Ã— 10 = Minimum data needed
  2.7M Ã— 10 = 27M images needed!

Waste data chá»‰ cÃ³:
  19,723 images << 27M images

â†’ Train from scratch = OVERFITTING!
```

**Minh há»a:**

```
Train from Scratch vá»›i Ã­t data:
Epoch 1:  Train=65%, Val=60%  âœ“ Learning
Epoch 10: Train=85%, Val=70%  âš  Gap tÄƒng
Epoch 20: Train=95%, Val=65%  âœ— OVERFITTING!
          â†‘                â†‘
     Memorizing        Not generalizing

Transfer Learning vá»›i Ã­t data:
Epoch 1:  Train=85%, Val=83%  âœ“ Already good!
Epoch 10: Train=94%, Val=93%  âœ“ Learning well
Epoch 20: Train=95%, Val=94%  âœ… EXCELLENT!
          â†‘                â†‘
     Small gap         Generalizing
```

---

### **B. Feature Reusability**

**Key Insight:**

```
Low-level features (edges, textures) lÃ  UNIVERSAL!
â†’ Giá»‘ng nhau across different datasets!
```

**VÃ­ dá»¥:**

```
ImageNet (1000 classes):
  - Cats, dogs, cars, trees, ...
  - Features learned:
    Layer 1: Edges (vertical, horizontal)
    Layer 2: Textures (fur, metal, wood)
    Layer 3: Shapes (circles, rectangles)
    Layer 4: Object parts (wheels, eyes)

Waste Classification (10 classes):
  - Plastic, glass, metal, ...
  - Features needed:
    Layer 1: Edges âœ… SAME as ImageNet!
    Layer 2: Textures âœ… SAME as ImageNet!
    Layer 3: Shapes âœ… SAME as ImageNet!
    Layer 4: Object parts âš  Different, need fine-tuning

â†’ DÃ¹ng láº¡i Layer 1-3 tá»« ImageNet!
â†’ Chá»‰ cáº§n há»c láº¡i Layer 4 cho waste!
```

**Visualize:**

```
ImageNet Features (Transferable):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 1: Edges                   â”‚ â† REUSE
â”‚ Layer 2: Textures                â”‚ â† REUSE
â”‚ Layer 3: Basic Shapes            â”‚ â† REUSE
â”‚ Layer 4: ImageNet-specific parts â”‚ â† FINE-TUNE
â”‚ Layer 5: ImageNet classes (1000) â”‚ â† REPLACE
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Waste Classifier (Transfer):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 1: Edges (from ImageNet)   â”‚ âœ“ Frozen
â”‚ Layer 2: Textures (from ImageNet)â”‚ âœ“ Frozen
â”‚ Layer 3: Shapes (from ImageNet)  â”‚ âœ“ Frozen
â”‚ Layer 4: Waste-specific patterns â”‚ âœ“ Fine-tuned
â”‚ Layer 5: Waste classes (10)      â”‚ âœ“ Trained
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### **C. Training Time**

```
Baseline CNN (Train from Scratch):
  - 30 epochs
  - ~2 mins/epoch
  - Total: ~60 minutes
  - Result: 79.59%

MobileNetV2 (Transfer Learning):
  Phase 1 (Feature Extraction):
    - 20 epochs
    - ~1.5 mins/epoch
    - Subtotal: ~30 mins

  Phase 2 (Fine-Tuning):
    - 15 epochs
    - ~2 mins/epoch
    - Subtotal: ~30 mins

  Total: ~60 minutes
  Result: 93.90%

â†’ CÃ™NG THá»œI GIAN, nhÆ°ng ACCURACY CAO HÆ N 14.31%!
```

---

## ğŸ—ï¸ 3. IMAGENET PRE-TRAINING (15 phÃºt)

### **A. ImageNet Dataset**

```
ImageNet ILSVRC:
  - 1.2 million training images
  - 1,000 classes
  - Classes: animals, vehicles, objects, ...

Examples:
  - Class 1: Persian cat
  - Class 2: Golden retriever
  - Class 281: Tabby cat
  - Class 817: Sports car
  - ...
  - Class 1000: Toilet paper
```

**Táº¡i sao ImageNet quan trá»ng?**

```
âœ… LARGE-SCALE: 1.2M images >> 19K waste images
âœ… DIVERSE: 1000 classes â†’ Rich features
âœ… HIGH-QUALITY: Human-annotated labels
âœ… STANDARD: Industry benchmark
```

---

### **B. Pre-trained Weights**

**MobileNetV2 trained on ImageNet:**

```
Training process:
  1. Random initialize weights
  2. Train 100+ epochs on ImageNet
  3. Achieve ~72% Top-1 accuracy (on 1000 classes!)
  4. Save weights â†’ "imagenet weights"

Learned features:
  Early layers: Generic (edges, textures)
  Middle layers: Mid-level (object parts)
  Late layers: Specific (ImageNet classes)
```

**Downloading pretrained weights:**

```python
# Keras automatically downloads ImageNet weights
base_model = tf.keras.applications.MobileNetV2(
    input_shape=(224, 224, 3),
    include_top=False,  # Exclude ImageNet classifier
    weights='imagenet'  # Load pretrained weights
)

# Weights downloaded from:
# https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/...
# Size: ~14 MB
```

---

### **C. Feature Hierarchy**

```
MobileNetV2 Pretrained on ImageNet:

Layer Group 1 (Early Layers):
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Edges, Colors       â”‚ â† GENERIC (transferable)
  â”‚ - Vertical edges    â”‚
  â”‚ - Horizontal edges  â”‚
  â”‚ - Diagonal edges    â”‚
  â”‚ - Color blobs       â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Layer Group 2 (Middle Layers):
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Textures, Patterns  â”‚ â† SEMI-GENERIC (transferable)
  â”‚ - Fur texture       â”‚
  â”‚ - Metal shine       â”‚
  â”‚ - Wood grain        â”‚
  â”‚ - Glass clarity     â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Layer Group 3 (Late Layers):
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Object Parts        â”‚ â† SEMI-SPECIFIC (fine-tune)
  â”‚ - Animal ears       â”‚
  â”‚ - Car wheels        â”‚
  â”‚ - Bottle shapes     â”‚ â† Useful for waste!
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Layer Group 4 (Final Layers):
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ ImageNet Classes    â”‚ â† SPECIFIC (replace)
  â”‚ - Cat vs Dog        â”‚
  â”‚ - Car vs Truck      â”‚
  â”‚ (NOT useful)        â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Transfer strategy:**

```
âœ“ FREEZE Layer Group 1 (Generic features)
âœ“ FREEZE Layer Group 2 (Textures)
âš  FINE-TUNE Layer Group 3 (Object parts)
âœ— REPLACE Layer Group 4 (Classifier)
```

---

## ğŸ”§ 4. FEATURE EXTRACTION VS FINE-TUNING (25 phÃºt)

### **A. Feature Extraction (Phase 1)**

**Concept:**

```
Feature Extraction = DÃ¹ng pretrained model nhÆ° FEATURE EXTRACTOR

Pretrained Model:
  Input â†’ [Frozen Layers] â†’ Features â†’ [New Classifier] â†’ Output
          â†‘ NOT trained          â†‘ Trained
```

**Implementation:**

```python
# 1. Load pretrained model
base_model = MobileNetV2(weights='imagenet', include_top=False)

# 2. FREEZE all layers
base_model.trainable = False  # â† KEY!

# 3. Add new classifier
model = keras.Sequential([
    base_model,                          # Frozen feature extractor
    layers.GlobalAveragePooling2D(),
    layers.Dense(256, activation='relu'),
    layers.Dropout(0.3),
    layers.Dense(10, activation='softmax')  # 10 waste classes
])

# 4. Compile & Train
model.compile(
    optimizer=Adam(lr=1e-4),  # Lower LR for stability
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

history = model.fit(train_ds, epochs=20, validation_data=val_ds)
```

**Táº¡i sao freeze base_model?**

```
Pretrained weights Ä‘Ã£ Tá»T:
  âœ“ Learned on 1.2M images
  âœ“ Generic features work well
  âœ“ Don't want to DESTROY them!

If NOT frozen:
  âœ— Random new classifier weights
  âœ— Large gradients backprop to base_model
  âœ— DESTROY pretrained features!
  âœ— Result: Worse than baseline!

Frozen:
  âœ“ Preserve pretrained features
  âœ“ Only train new classifier
  âœ“ Stable training
  âœ“ Fast convergence
```

**Training dynamics:**

```
Phase 1: Feature Extraction (20 epochs)

Epoch 1:  Val Acc = 85.12%  â† Already GOOD! (vs Baseline 70%)
  â†’ Pretrained features work well!

Epoch 5:  Val Acc = 90.34%
  â†’ New classifier adapting

Epoch 10: Val Acc = 92.10%
  â†’ Near convergence

Epoch 20: Val Acc = 92.78%
  â†’ PLATEAU (classifier learned)
```

---

### **B. Fine-Tuning (Phase 2)**

**Concept:**

```
Fine-Tuning = UN-FREEZE some layers, train vá»›i LR Ráº¤T THáº¤P

Pretrained Model:
  Input â†’ [Frozen Early] â†’ [Trainable Late] â†’ [Classifier] â†’ Output
          â†‘ Still frozen   â†‘ Fine-tuned       â†‘ Already trained
```

**Táº¡i sao Fine-Tuning?**

```
After Phase 1:
  âœ“ Classifier learned (92.78%)
  âš  Base model features still "ImageNet-specific"
  âš  Not perfectly adapted to waste data

Phase 2 Goal:
  â†’ Adapt high-level features to waste domain
  â†’ Improve 92.78% â†’ 93.90%
```

**Implementation:**

```python
# 1. UN-FREEZE base model
base_model.trainable = True

# 2. FREEZE early layers (keep generic features)
fine_tune_at = 100  # Freeze first 100 layers

for layer in base_model.layers[:fine_tune_at]:
    layer.trainable = False  # Keep frozen

for layer in base_model.layers[fine_tune_at:]:
    layer.trainable = True   # Fine-tune these

# 3. Compile with VERY LOW learning rate
model.compile(
    optimizer=Adam(lr=1e-5),  # 10x smaller than Phase 1!
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# 4. Fine-tune
history_fine = model.fit(
    train_ds,
    epochs=15,
    validation_data=val_ds,
    initial_epoch=20  # Continue from Phase 1
)
```

**Táº¡i sao LR Ráº¤T THáº¤P?**

```
High LR (1e-4):
  â†’ Large weight updates
  â†’ DESTROY pretrained features!
  â†’ Overfitting!

Very Low LR (1e-5):
  â†’ Small, careful updates
  â†’ Gently adapt features
  â†’ Preserve pretrained knowledge
  â†’ Stable fine-tuning
```

**Training dynamics:**

```
Phase 2: Fine-Tuning (15 epochs)

Epoch 21: Val Acc = 92.95%  (+0.17% from Phase 1)
  â†’ Late layers adapting

Epoch 25: Val Acc = 93.45%  (+0.50%)
  â†’ Learning waste-specific patterns

Epoch 30: Val Acc = 93.78%  (+0.33%)
  â†’ Approaching optimal

Epoch 35: Val Acc = 93.90%  (+0.12%)
  â†’ BEST RESULT!
  â†’ EarlyStopping (val_loss not improving)
```

---

### **C. Comparison Table**

| Aspect | Feature Extraction | Fine-Tuning |
|--------|-------------------|-------------|
| **Base Model** | Frozen (not trained) | Partially frozen |
| **Trainable Layers** | Only new classifier | Late layers + classifier |
| **Learning Rate** | 1e-4 (moderate) | 1e-5 (very low) |
| **Training Time** | Fast (20 epochs) | Moderate (15 epochs) |
| **Risk** | Low (safe) | Medium (can destroy features) |
| **Accuracy** | 92.78% | 93.90% (+1.12%) |
| **When to use** | Always start here | After Feature Extraction |

---

## ğŸ“Š 5. TWO-PHASE TRAINING STRATEGY (20 phÃºt)

### **A. Why Two Phases?**

**Problem náº¿u Fine-Tune ngay tá»« Ä‘áº§u:**

```
Scenario: Fine-tune all layers tá»« epoch 1

base_model.trainable = True  # ALL layers trainable
model.compile(optimizer=Adam(lr=1e-5))
model.fit(...)

Result:
  Epoch 1:  Val Acc = 72%  â† Sá»¤T so vá»›i baseline!
  Epoch 10: Val Acc = 78%
  Epoch 30: Val Acc = 85%  â† Worse than 2-phase!

Táº¡i sao?
  âœ— New classifier weights = RANDOM
  âœ— Large gradients tá»« random classifier
  âœ— Backprop â†’ Destroy pretrained features!
  âœ— Model pháº£i há»c láº¡i tá»« Ä‘áº§u (but vá»›i LR tháº¥p â†’ slow!)
```

**Solution: Two-Phase Training**

```
Phase 1: Feature Extraction (Frozen base)
  â†’ Train ONLY new classifier
  â†’ Classifier learns to use pretrained features
  â†’ Safe, stable, fast convergence
  â†’ Result: 92.78%

Phase 2: Fine-Tuning (Partial unfreeze)
  â†’ Classifier Ä‘Ã£ tá»‘t rá»“i (not random!)
  â†’ Now safe to fine-tune late layers
  â†’ Small LR â†’ Gentle adaptation
  â†’ Result: 93.90% (+1.12%)
```

---

### **B. Layer Freezing Strategy**

**MobileNetV2 Architecture (53 layers):**

```
Layers 0-30 (Early):
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Generic Features     â”‚ â† ALWAYS FROZEN
  â”‚ - Edges, colors      â”‚
  â”‚ - Basic textures     â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Layers 31-100 (Middle):
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Mid-level Features   â”‚ â† FROZEN in Phase 1 & 2
  â”‚ - Textures, patterns â”‚   (Generic enough)
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Layers 101-154 (Late):
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ High-level Features  â”‚ â† FROZEN in Phase 1
  â”‚ - Object parts       â”‚ â† TRAINABLE in Phase 2
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

New Classifier:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Waste Classes (10)   â”‚ â† TRAINABLE in both phases
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Code:**

```python
# Phase 1: ALL base_model frozen
base_model.trainable = False

# Phase 2: Partially frozen
base_model.trainable = True
fine_tune_at = 100

for layer in base_model.layers[:fine_tune_at]:
    layer.trainable = False  # Layers 0-99: FROZEN
for layer in base_model.layers[fine_tune_at:]:
    layer.trainable = True   # Layers 100-154: TRAINABLE
```

---

### **C. Learning Rate Schedule**

```
Phase 1: Feature Extraction
  Initial LR: 1e-4 (0.0001)

  Epoch 1-10:  LR = 1e-4
  Epoch 11-15: LR = 5e-5  (ReduceLROnPlateau)
  Epoch 16-20: LR = 2.5e-5

Phase 2: Fine-Tuning
  Initial LR: 1e-5 (0.00001)  â† 10x smaller!

  Epoch 21-30: LR = 1e-5
  Epoch 31-35: LR = 5e-6  (ReduceLROnPlateau)
```

**Visualize:**

```
Learning Rate over Time

LR
 â†‘
1e-4 â”¤â”€â”€â”€â”€â”€â•²
     â”‚      â•²___
     â”‚          â•²__
     â”‚             â•²  Phase 1
     â”‚              â•²__
1e-5 â”¤                 â”€â”€â”€â”€â”€â•²  Phase 2
     â”‚                       â•²__
     â”‚                          â•²
1e-6 â”¤                           â”€â”€
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Epochs
     0     10    20    30    35
```

---

### **D. Complete Training Process**

```python
# ===== PHASE 1: FEATURE EXTRACTION (20 epochs) =====

# 1. Build model with frozen base
base_model = MobileNetV2(weights='imagenet', include_top=False)
base_model.trainable = False  # Freeze

model = keras.Sequential([
    base_model,
    GlobalAveragePooling2D(),
    Dense(256, activation='relu'),
    Dropout(0.3),
    Dense(10, activation='softmax')
])

# 2. Compile
model.compile(
    optimizer=Adam(lr=1e-4),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# 3. Train Phase 1
history_phase1 = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=20,
    callbacks=[
        EarlyStopping(patience=5),
        ReduceLROnPlateau(patience=3, factor=0.5)
    ]
)
# Result: Val Acc = 92.78%

# ===== PHASE 2: FINE-TUNING (15 epochs) =====

# 4. Unfreeze late layers
base_model.trainable = True
for layer in base_model.layers[:100]:
    layer.trainable = False

# 5. Recompile with lower LR
model.compile(
    optimizer=Adam(lr=1e-5),  # 10x lower!
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# 6. Train Phase 2
history_phase2 = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=15,
    initial_epoch=20,  # Continue from Phase 1
    callbacks=[
        EarlyStopping(patience=5),
        ReduceLROnPlateau(patience=3, factor=0.5)
    ]
)
# Result: Val Acc = 93.90% (+1.12%)
```

---

## ğŸ“ˆ 6. RESULTS COMPARISON (15 phÃºt)

### **A. Accuracy Comparison**

```
Train from Scratch (Baseline CNN):
  Train Acc: 81.28%
  Val Acc:   79.59%
  Test Acc:  79.51%
  Gap:       1.69%

Transfer Learning (MobileNetV2):
  Phase 1 only:
    Train Acc: 93.12%
    Val Acc:   92.78%
    Gap:       0.34%  â† Very good!

  Phase 1 + 2 (Full):
    Train Acc: 94.56%
    Val Acc:   94.00%
    Test Acc:  93.90%
    Gap:       0.56%  â† Excellent generalization!

Improvement:
  93.90% - 79.51% = +14.39 percentage points!
  (+18.1% relative improvement!)
```

---

### **B. Training Curves**

```
Baseline CNN:
Val Acc
  â†‘
80% â”¤                     â”€â”€â”€â”€â”€â”€â”€  â† Plateau at 79.5%
    â”‚                â•±â•±â•±â•±
70% â”¤          â•±â•±â•±â•±â•±
    â”‚     â•±â•±â•±â•±
60% â”¤â•±â•±â•±â•±
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Epochs
    0   5   10  15  20  25  30

Transfer Learning:
Val Acc
  â†‘
94% â”¤                         â”€â”€â”€â”€  â† Phase 2 fine-tuning
    â”‚                    â•±â•±â•±â•±
92% â”¤              â”€â”€â”€â”€â”€â”€           â† Phase 1 plateau
    â”‚         â•±â•±â•±â•±â•±
88% â”¤    â•±â•±â•±â•±
    â”‚â•±â•±â•±â•±
84% â”¤
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Epochs
    0   5   10  15  20  25  30  35
           Phase 1      Phase 2
```

---

### **C. Per-Class Improvement**

```
Class Performance (Baseline â†’ MobileNetV2):

Easy Classes:
  clothes:    94.10% â†’ 96.50% (+2.40%)  âœ“ Good
  shoes:      89.90% â†’ 95.20% (+5.30%)  âœ“ Great

Medium Classes:
  paper:      81.70% â†’ 92.80% (+11.10%) âœ… Excellent!
  plastic:    78.30% â†’ 93.40% (+15.10%) âœ… Huge!
  cardboard:  83.40% â†’ 94.10% (+10.70%) âœ… Great

Hard Classes:
  trash:      52.11% â†’ 82.30% (+30.19%) ğŸ”¥ MASSIVE!
  glass:      74.50% â†’ 89.70% (+15.20%) âœ… Huge!
  metal:      76.20% â†’ 91.50% (+15.30%) âœ… Huge!

â†’ Transfer Learning giÃºp NHIá»€U NHáº¤T vá»›i hard classes!
```

---

## ğŸ“ Tá»”NG Káº¾T

### **Key Concepts:**

1. **Transfer Learning** = DÃ¹ng pretrained weights from ImageNet
2. **Two-Phase Training:**
   - Phase 1: Feature Extraction (frozen base)
   - Phase 2: Fine-Tuning (partial unfreeze)
3. **Feature Reusability:** Low-level features transferable across domains
4. **Data Efficiency:** 19K images Ä‘á»§ vá»›i Transfer Learning

### **Why Transfer Learning >> Baseline:**

```
âœ… Pretrained on 1.2M images (vs 15K waste images)
âœ… Deeper architecture (53 layers vs 8)
âœ… Better features (learned from diverse data)
âœ… Less overfitting (pretrained = regularization)
âœ… Faster convergence (start from good features)
```

### **Results:**

```
Baseline:        79.51%
Transfer:        93.90%
Improvement:     +14.39 percentage points! âœ…
```

---

## âœ… CHECKPOINT

**Báº¡n cáº§n hiá»ƒu Ä‘Æ°á»£c:**

- [ ] Transfer Learning dÃ¹ng pretrained ImageNet weights
- [ ] Two-phase training: Feature Extraction â†’ Fine-Tuning
- [ ] Phase 1: Freeze base, train classifier (1e-4 LR)
- [ ] Phase 2: Unfreeze late layers, fine-tune (1e-5 LR)
- [ ] Low-level features transferable across domains
- [ ] Transfer Learning tá»‘t hÆ¡n vÃ¬ pretrained on 1.2M images
- [ ] MobileNetV2 Ä‘áº¡t 93.90% (+14.39% vs Baseline)

**Náº¿u OK â†’** Tiáº¿p tá»¥c `05_MobileNetV2_Thuc_Hanh.md` ğŸš€
