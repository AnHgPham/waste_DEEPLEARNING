# ğŸ–¼ï¸ CNN & COMPUTER VISION

**Thá»i gian:** 1.5 giá»
**Má»¥c tiÃªu:** Hiá»ƒu CNN extract features tá»« áº£nh nhÆ° tháº¿ nÃ o

---

## ğŸ“Œ 1. Táº I SAO Cáº¦N CNN? (10 phÃºt)

### **Váº¥n Ä‘á» vá»›i Neural Network thÆ°á»ng:**

```python
# áº¢nh 224x224x3
pixels = 224 * 224 * 3 = 150,528 pixels

# Fully Connected Neural Network:
Input Layer: 150,528 neurons
Hidden: 1,000 neurons

â†’ Weights = 150,528 * 1,000 = 150M parameters!
â†’ QUÃ NHIá»€U! Overfitting ngay!
```

**Problems:**
- âŒ QuÃ¡ nhiá»u parameters
- âŒ KhÃ´ng táº­n dá»¥ng spatial structure (vá»‹ trÃ­ pixels)
- âŒ KhÃ´ng há»c Ä‘Æ°á»£c local patterns (cáº¡nh, gÃ³c...)

---

### **Giáº£i phÃ¡p: CNN (Convolutional Neural Network)**

**Ã tÆ°á»Ÿng:** Thay vÃ¬ nhÃ¬n Táº¤T Cáº¢ pixels cÃ¹ng lÃºc â†’ NhÃ¬n tá»«ng **vÃ¹ng nhá»**!

```
Fully Connected:        CNN:
NhÃ¬n toÃ n bá»™ áº£nh       NhÃ¬n tá»«ng vÃ¹ng 3x3
[224x224]              [3x3] â†’ TrÆ°á»£t qua áº£nh

ğŸ”²ğŸ”²ğŸ”²ğŸ”²ğŸ”²              ğŸ”[3x3]
ğŸ”²ğŸ”²ğŸ”²ğŸ”²ğŸ”²              ğŸ”²ğŸ”²ğŸ”²ğŸ”²ğŸ”²
ğŸ”²ğŸ”²ğŸ”²ğŸ”²ğŸ”²   VS        ğŸ”²ğŸ”²ğŸ”²ğŸ”²ğŸ”²
ğŸ”²ğŸ”²ğŸ”²ğŸ”²ğŸ”²              ğŸ”²ğŸ”²ğŸ”²ğŸ”²ğŸ”²
ğŸ”²ğŸ”²ğŸ”²ğŸ”²ğŸ”²              ğŸ”²ğŸ”²ğŸ”²ğŸ”²ğŸ”²
```

**Lá»£i Ã­ch:**
- âœ… Ãt parameters hÆ¡n nhiá»u!
- âœ… Há»c Ä‘Æ°á»£c local patterns (edges, corners...)
- âœ… Translation invariant (khÃ´ng quan tÃ¢m vá»‹ trÃ­)

---

## ğŸ” 2. CONVOLUTION LÃ€ GÃŒ? (20 phÃºt)

### **Äá»‹nh nghÄ©a:**

**Convolution = TrÆ°á»£t 1 filter (kernel) qua áº£nh Ä‘á»ƒ extract features**

### **VÃ­ dá»¥ trá»±c quan:**

```
Input Image (5x5):          Filter/Kernel (3x3):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1  1  1  0  0  â”‚         â”‚ 1  0  1 â”‚
â”‚ 0  1  1  1  0  â”‚         â”‚ 0  1  0 â”‚
â”‚ 0  0  1  1  1  â”‚         â”‚ 1  0  1 â”‚
â”‚ 0  0  1  1  0  â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ 0  1  1  0  0  â”‚         Edge Detector
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**BÆ°á»›c 1: Filter á»Ÿ gÃ³c trÃ¡i trÃªn**

```
Input:              Filter:         Computation:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1  1  1â”‚          â”‚ 1  0  1 â”‚     1*1 + 1*0 + 1*1 = 2
â”‚ 0  1  1â”‚  âœ•       â”‚ 0  1  0 â”‚  +  0*0 + 1*1 + 1*0 = 1
â”‚ 0  0  1â”‚          â”‚ 1  0  1 â”‚  +  0*1 + 0*0 + 1*1 = 1
â””â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                                    Result = 4
```

**BÆ°á»›c 2: TrÆ°á»£t sang pháº£i (stride=1)**

```
Input:              Filter:         Computation:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1  1  1  0â”‚      â”‚ 1  0  1 â”‚     1*1 + 1*0 + 1*1 = 2
â”‚  1  1  1  0â”‚  âœ•   â”‚ 0  1  0 â”‚  +  1*0 + 1*1 + 1*0 = 1
â”‚  0  1  1  1â”‚      â”‚ 1  0  1 â”‚  +  0*1 + 1*0 + 1*1 = 1
  â””â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                                    Result = 4
```

**Tiáº¿p tá»¥c trÆ°á»£t... â†’ Output Feature Map:**

```
Output (3x3):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4  3  4 â”‚
â”‚ 2  4  3 â”‚
â”‚ 2  3  4 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Feature Map (detected edges!)
```

---

### **CÃ¡c loáº¡i filters phá»• biáº¿n:**

#### **1. Edge Detection (Vertical)**

```
Filter:                 Detects:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚ â”‚ â”‚ â”‚
â”‚ 1   0  -1â”‚           â”‚ â”‚ â”‚ â”‚  Vertical edges
â”‚ 1   0  -1â”‚           â”‚ â”‚ â”‚ â”‚
â”‚ 1   0  -1â”‚           â”‚ â”‚ â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### **2. Edge Detection (Horizontal)**

```
Filter:                 Detects:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚ 1   1   1â”‚           â”€â”€â”€â”€â”€â”€â”€â”€â”€  Horizontal edges
â”‚ 0   0   0â”‚           â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚-1  -1  -1â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### **3. Sharpen**

```
Filter:                 Effect:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           Makes image sharper
â”‚ 0  -1   0â”‚
â”‚-1   5  -1â”‚
â”‚ 0  -1   0â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### **4. Blur**

```
Filter (average):       Effect:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      Smooths image
â”‚ 1/9  1/9  1/9 â”‚
â”‚ 1/9  1/9  1/9 â”‚
â”‚ 1/9  1/9  1/9 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### **Multiple Channels (RGB):**

```
Input: 224x224x3 (RGB)

Filter: 3x3x3 (matches input channels!)
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ R filterâ”‚  3x3
  â”‚ G filterâ”‚  3x3
  â”‚ B filterâ”‚  3x3
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Convolution:
R_out = conv(R_input, R_filter)
G_out = conv(G_input, G_filter)
B_out = conv(B_input, B_filter)

Output = R_out + G_out + B_out  â†’ 1 feature map!
```

---

### **Multiple Filters:**

```
Input: 224x224x3

32 Filters (each 3x3x3)
â†’ 32 Feature Maps (each 224x224)
â†’ Output: 224x224x32

Conv2D(32 filters, 3x3):
Input  [224, 224, 3]
        â†“
Output [224, 224, 32]  (if padding='same')
```

---

## ğŸ“ 3. PADDING, STRIDE, POOLING (15 phÃºt)

### **A. Padding**

**Váº¥n Ä‘á»:** Convolution lÃ m áº£nh nhá» Ä‘i!

```
Input: 5x5 â†’ Conv 3x3 â†’ Output: 3x3
Input: 224x224 â†’ Conv 3x3 â†’ Output: 222x222
```

**Giáº£i phÃ¡p: Zero Padding**

```
Original (5x5):          With Padding (7x7):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1  1  1  0  0â”‚        â”‚ 0  0  0  0  0  0  0â”‚
â”‚ 0  1  1  1  0â”‚        â”‚ 0  1  1  1  0  0  0â”‚
â”‚ 0  0  1  1  1â”‚   â†’    â”‚ 0  0  1  1  1  0  0â”‚
â”‚ 0  0  1  1  0â”‚        â”‚ 0  0  0  1  1  1  0â”‚
â”‚ 0  1  1  0  0â”‚        â”‚ 0  0  0  1  1  0  0â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚ 0  0  1  1  0  0  0â”‚
                        â”‚ 0  0  0  0  0  0  0â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Conv 3x3 â†’ Output still 5x5! âœ…
```

**Trong code:**

```python
# Keras/TensorFlow
Conv2D(32, (3,3), padding='same')   # Output size = Input size
Conv2D(32, (3,3), padding='valid')  # Output size shrinks
```

---

### **B. Stride**

**Stride = BÆ°á»›c nháº£y khi trÆ°á»£t filter**

```
Stride = 1 (default):     Stride = 2:
Move 1 pixel              Move 2 pixels

[â–ˆâ–ˆâ–ˆ]â–¡â–¡â–¡â–¡                 [â–ˆâ–ˆâ–ˆ]â–¡â–¡â–¡â–¡
â–¡[â–ˆâ–ˆâ–ˆ]â–¡â–¡                  â–¡â–¡[â–ˆâ–ˆâ–ˆ]â–¡
â–¡â–¡[â–ˆâ–ˆâ–ˆ]â–¡                  â–¡â–¡â–¡â–¡[â–ˆâ–ˆâ–ˆ]
â–¡â–¡â–¡[â–ˆâ–ˆâ–ˆ]

Output: Large            Output: Half size!
```

**VÃ­ dá»¥:**

```python
Input: 224x224

Conv2D(32, (3,3), stride=1) â†’ Output: 224x224 (with padding)
Conv2D(32, (3,3), stride=2) â†’ Output: 112x112 (downsampling!)
```

---

### **C. Pooling** â­ QUAN TRá»ŒNG

**Pooling = Downsample feature maps**

#### **Max Pooling (phá»• biáº¿n nháº¥t):**

```
Input (4x4):               Max Pool 2x2:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1  3  2  4  â”‚          â”‚ 3  4  â”‚  â† max of each 2x2
â”‚ 5  6  7  8  â”‚    â†’     â”‚ 14 16 â”‚
â”‚ 9 10 11 12  â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚13 14 15 16  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Process:
[1 3]        [2 4]
[5 6]  â†’ 6   [7 8]  â†’ 8

[9 10]       [11 12]
[13 14] â†’ 14 [15 16] â†’ 16
```

**Táº¡i sao dÃ¹ng Pooling?**
- âœ… Giáº£m kÃ­ch thÆ°á»›c (less computation)
- âœ… Giáº£m overfitting
- âœ… Translation invariance (nháº­n dáº¡ng object dÃ¹ vá»‹ trÃ­ thay Ä‘á»•i)

**Trong code:**

```python
MaxPooling2D(pool_size=(2, 2))  # Giáº£m 50% size

Input:  224x224x32
        â†“
Output: 112x112x32  (height, width /2)
```

---

## ğŸ—ï¸ 4. CNN ARCHITECTURE (30 phÃºt)

### **Typical CNN Structure:**

```
Input Image
    â†“
[Convolutional Block] Ã—N
    â†“
[Flatten]
    â†“
[Dense Layers]
    â†“
Output (classes)
```

---

### **Convolutional Block:**

```
Input
    â†“
Convolution (extract features)
    â†“
Activation (ReLU)
    â†“
Pooling (downsample)
    â†“
Output
```

---

### **VÃ­ dá»¥: Baseline CNN trong dá»± Ã¡n**

```python
# src/models/baseline.py

Input: 224x224x3
    â†“
Rescaling (0-1)
    â†“
# Block 1
Conv2D(32, 3x3) â†’ 224x224x32
ReLU
Conv2D(32, 3x3) â†’ 224x224x32
ReLU
BatchNorm
MaxPool(2x2) â†’ 112x112x32
    â†“
# Block 2
Conv2D(64, 3x3) â†’ 112x112x64
ReLU
Conv2D(64, 3x3) â†’ 112x112x64
ReLU
BatchNorm
MaxPool(2x2) â†’ 56x56x64
    â†“
# Block 3
Conv2D(128, 3x3) â†’ 56x56x128
ReLU
Conv2D(128, 3x3) â†’ 56x56x128
ReLU
BatchNorm
MaxPool(2x2) â†’ 28x28x128
    â†“
# Block 4
Conv2D(256, 3x3) â†’ 28x28x256
ReLU
Conv2D(256, 3x3) â†’ 28x28x256
ReLU
BatchNorm
MaxPool(2x2) â†’ 14x14x256
    â†“
GlobalAvgPool â†’ 256
    â†“
Dense(128) + Dropout(0.5)
    â†“
Dense(10, softmax)
    â†“
Output: [plastic prob, glass prob, ...]
```

---

### **Feature Hierarchy (PhÃ¢n cáº¥p Ä‘áº·c trÆ°ng):**

```
Early Layers (Block 1-2):
â”œâ”€ Edges (cáº¡nh)
â”œâ”€ Corners (gÃ³c)
â””â”€ Simple textures (vÃ¢n Ä‘Æ¡n giáº£n)

Mid Layers (Block 3):
â”œâ”€ Complex textures
â”œâ”€ Patterns (há»a tiáº¿t)
â””â”€ Parts (bá»™ pháº­n nhá»)

Deep Layers (Block 4):
â”œâ”€ Object parts (náº¯p chai, nhÃ£n)
â”œâ”€ Shapes (hÃ¬nh dáº¡ng)
â””â”€ High-level features

Final Layers:
â””â”€ Complete objects (plastic bottle, glass jar...)
```

**Visualize:**

```
Layer 1: Detects       Layer 3: Detects         Layer 5: Detects
â”‚ â”‚ â”€                 Textures                  Objects
â”‚ â”‚ â”€                 â•±â•²â•±â•²                      ğŸ¾ Bottle
\ / âˆ                  â–‘â–’â–“â–ˆ                      ğŸ¥« Can
```

---

## ğŸ“Š 5. IMAGE CLASSIFICATION WORKFLOW (15 phÃºt)

### **Complete Pipeline:**

```
1. DATA LOADING
   â””â”€ Load images from folders
   â””â”€ Resize to 224x224
   â””â”€ Normalize [0, 255] â†’ [0, 1]

2. DATA AUGMENTATION
   â””â”€ Random flip, rotation
   â””â”€ Zoom, brightness change
   â””â”€ â†’ Increase diversity!

3. MODEL DEFINITION
   â””â”€ Define CNN architecture
   â””â”€ Compile (loss, optimizer)

4. TRAINING
   â””â”€ Forward prop (predict)
   â””â”€ Calculate loss
   â””â”€ Backprop (gradients)
   â””â”€ Update weights
   â””â”€ Repeat for all epochs

5. EVALUATION
   â””â”€ Test on unseen data
   â””â”€ Calculate accuracy
   â””â”€ Analyze errors

6. DEPLOYMENT
   â””â”€ Save model
   â””â”€ Optimize (TFLite)
   â””â”€ Deploy to production
```

---

### **Trong dá»± Ã¡n:**

```python
# 1. Load Data
train_ds = image_dataset_from_directory(
    TRAIN_DIR,
    image_size=(224, 224),
    batch_size=32
)

# 2. Data Augmentation
augmentation = Sequential([
    RandomFlip("horizontal"),
    RandomRotation(0.2),
    RandomZoom(0.2)
])

# 3. Build Model
model = build_baseline_model(
    input_shape=(224, 224, 3),
    num_classes=10
)

# 4. Compile
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# 5. Train
history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=30
)

# 6. Evaluate
test_loss, test_acc = model.evaluate(test_ds)
print(f"Test Accuracy: {test_acc:.4f}")
```

---

## ğŸ¨ 6. DATA AUGMENTATION (10 phÃºt)

**Táº¡i sao cáº§n?** â†’ TÄƒng Ä‘a dáº¡ng dá»¯ liá»‡u, giáº£m overfitting!

### **CÃ¡c ká»¹ thuáº­t phá»• biáº¿n:**

#### **1. Horizontal Flip**

```
Original:              Flipped:
ğŸ¾                     ğŸ¾
â”‚  Bottle              Bottle  â”‚
â”‚  facing right        facing left
```

#### **2. Rotation**

```
Original:              Rotated 20Â°:
   ğŸ¾                    â•±ğŸ¾
   â”‚                   â•±  â”‚
   â”‚                 â•±    â”‚
```

#### **3. Zoom**

```
Original:              Zoomed In:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”
â”‚            â”‚        â”‚ ğŸ¾   â”‚
â”‚    ğŸ¾      â”‚   â†’    â”‚ â”‚ â”‚  â”‚
â”‚    â”‚ â”‚     â”‚        â”‚ â”‚ â”‚  â”‚
â”‚    â”‚ â”‚     â”‚        â””â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        (closer view)
```

#### **4. Brightness**

```
Original:              Darker:        Lighter:
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               â–“â–“â–“â–“â–“â–“â–“        â–‘â–‘â–‘â–‘â–‘â–‘â–‘
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               â–“â–“â–“â–“â–“â–“â–“        â–‘â–‘â–‘â–‘â–‘â–‘â–‘
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               â–“â–“â–“â–“â–“â–“â–“        â–‘â–‘â–‘â–‘â–‘â–‘â–‘
```

#### **5. Contrast**

```
Original:              Higher Contrast:
â–ˆâ–ˆâ–“â–“â–’â–’â–‘â–‘              â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘
â–ˆâ–ˆâ–“â–“â–’â–’â–‘â–‘              â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘
```

---

### **Trong dá»± Ã¡n:**

```python
# src/data/preprocessing.py

augmentation = tf.keras.Sequential([
    layers.RandomFlip("horizontal"),
    layers.RandomRotation(0.2),          # Â±20%
    layers.RandomZoom(0.2),              # Â±20%
    layers.RandomContrast(0.2),
    layers.RandomBrightness(0.2),
    layers.RandomTranslation(0.1, 0.1)   # Shift 10%
])
```

**Káº¿t quáº£:**

```
1 áº£nh gá»‘c â†’ 100+ variations khÃ¡c nhau!

Original plastic bottle
â†’ Flipped
â†’ Rotated
â†’ Zoomed
â†’ Brightened
...

Effectively: 15,777 â†’ 1,000,000+ training samples!
```

---

## ğŸ“ Tá»”NG Káº¾T

### **CNN vs Fully Connected:**

| Aspect | Fully Connected | CNN |
|--------|----------------|-----|
| **Parameters** | ~150M | ~1.4M |
| **Local patterns** | âŒ No | âœ… Yes (filters) |
| **Spatial info** | âŒ Lost | âœ… Preserved |
| **Translation invariant** | âŒ No | âœ… Yes (pooling) |

---

### **Key Concepts:**

1. **Convolution** = TrÆ°á»£t filter qua áº£nh
2. **Filter** = Há»c detect features (edges, textures...)
3. **Pooling** = Downsample, giáº£m size
4. **Feature Hierarchy** = Low â†’ Mid â†’ High level
5. **Data Augmentation** = TÄƒng diversity

---

### **CNN Architecture Pattern:**

```
[Conv â†’ ReLU â†’ Pool] Ã— N â†’ Flatten â†’ Dense â†’ Output
```

---

## âœ… CHECKPOINT

**Báº¡n cáº§n hiá»ƒu Ä‘Æ°á»£c:**

- [ ] Táº¡i sao CNN tá»‘t hÆ¡n Fully Connected
- [ ] Convolution extract features báº±ng filters
- [ ] Padding, Stride, Pooling lÃ m gÃ¬
- [ ] CNN architecture: Conv blocks â†’ Dense
- [ ] Data Augmentation tÄƒng data diversity

**Náº¿u OK â†’** Tiáº¿p tá»¥c `03_Baseline_CNN_Chi_Tiet.md` ğŸš€

**Náº¿u chÆ°a hiá»ƒu â†’** Äá»c láº¡i pháº§n Convolution (quan trá»ng nháº¥t!)
